{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fcb529a",
   "metadata": {},
   "source": [
    "# tiktoken exploration using the tiktoken library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb83a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of genZ words to explore\n",
    "genz_words = [\n",
    "    \"lit\",\n",
    "    \"fam\",\n",
    "    \"vibe\",\n",
    "    \"slay\",\n",
    "    \"flex\",\n",
    "    \"skrrt\",\n",
    "    \"skibidi\",\n",
    "    \"sigma\",\n",
    "    \"delulu\",\n",
    "    \"sus\",\n",
    "    \"bussin\",\n",
    "    \"cap\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0d5d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-4 tokenizer\n",
    "gpt4_tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "# gpt-2 tokenizer\n",
    "gpt2_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# function to count tokens for a list of words\n",
    "def count_tokens(words, tokenizer):\n",
    "    return [len(tokenizer.encode(word)) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e46d19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 Token Counts:\n",
      "lit: 1 token(s)\n",
      "fam: 1 token(s)\n",
      "vibe: 2 token(s)\n",
      "slay: 2 token(s)\n",
      "flex: 1 token(s)\n",
      "skrrt: 3 token(s)\n",
      "skibidi: 3 token(s)\n",
      "sigma: 1 token(s)\n",
      "delulu: 2 token(s)\n",
      "sus: 1 token(s)\n",
      "bussin: 3 token(s)\n",
      "cap: 1 token(s)\n",
      "\n",
      "GPT-2 Token Counts:\n",
      "lit: 1 token(s)\n",
      "fam: 1 token(s)\n",
      "vibe: 2 token(s)\n",
      "slay: 2 token(s)\n",
      "flex: 1 token(s)\n",
      "skrrt: 3 token(s)\n",
      "skibidi: 3 token(s)\n",
      "sigma: 2 token(s)\n",
      "delulu: 2 token(s)\n",
      "sus: 2 token(s)\n",
      "bussin: 3 token(s)\n",
      "cap: 1 token(s)\n"
     ]
    }
   ],
   "source": [
    "# print token counts for gpt-4\n",
    "print(\"GPT-4 Token Counts:\")\n",
    "for word, count in zip(genz_words, count_tokens(genz_words, gpt4_tokenizer)):\n",
    "    print(f\"{word}: {count} token(s)\")\n",
    "# print token counts for gpt-2\n",
    "print(\"\\nGPT-2 Token Counts:\")\n",
    "for word, count in zip(genz_words, count_tokens(genz_words, gpt2_tokenizer)):\n",
    "    print(f\"{word}: {count} token(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34da22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_slang_terms = [\n",
    "    \"rizz\",             # charisma / flirting ability\n",
    "    \"girl dinner\",      # quirky meal made from snacks\n",
    "    \"delulu\",           # delusional in a funny or hopeful way\n",
    "    \"beige flag\",       # mildly weird dating trait\n",
    "    \"situationship\",    # undefined romantic relationship\n",
    "    \"sigma\",            # lone wolf masculinity type\n",
    "    \"main character\",   # person acting like theyâ€™re in a movie\n",
    "    \"quiet luxury\",     # expensive but understated fashion\n",
    "    \"npc\",              # acting robotic or emotionless\n",
    "    \"no thoughts, head empty\",  # blissfully unaware or relaxed\n",
    "    \"mid\",              # average or underwhelming\n",
    "    \"feral\",            # unhinged excitement or rage\n",
    "    \"canon event\",      # inevitable event that shapes someone\n",
    "    \"ate and left no crumbs\",  # performed extremely well\n",
    "    \"he's just a guy\",  # minimizing idolization of a man\n",
    "    \"loud budgeting\",   # openly refusing to overspend\n",
    "    \"chronically online\", # out of touch with real life\n",
    "    \"corecore\",         # emotional or aesthetic TikTok trend\n",
    "    \"ick\",              # sudden repulsion in dating\n",
    "    \"male manipulator music\",  # music associated with ironic red flags\n",
    "    \"Harvard travel ban\",\n",
    "    \"liberalism is a mental disorder\",\n",
    "    \"NPC energy\",       # robotic or emotionless behavior\n",
    "    \"girlboss\",         # empowered\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9eeff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 Token Counts:\n",
      "rizz: 2 token(s)\n",
      "girl dinner: 2 token(s)\n",
      "delulu: 2 token(s)\n",
      "beige flag: 3 token(s)\n",
      "situationship: 2 token(s)\n",
      "sigma: 1 token(s)\n",
      "main character: 2 token(s)\n",
      "quiet luxury: 2 token(s)\n",
      "npc: 1 token(s)\n",
      "no thoughts, head empty: 5 token(s)\n",
      "mid: 1 token(s)\n",
      "feral: 2 token(s)\n",
      "canon event: 2 token(s)\n",
      "ate and left no crumbs: 5 token(s)\n",
      "he's just a guy: 5 token(s)\n",
      "loud budgeting: 3 token(s)\n",
      "chronically online: 3 token(s)\n",
      "corecore: 2 token(s)\n",
      "ick: 1 token(s)\n",
      "male manipulator music: 4 token(s)\n",
      "Harvard travel ban: 4 token(s)\n",
      "liberalism is a mental disorder: 7 token(s)\n",
      "NPC energy: 2 token(s)\n",
      "girlboss: 2 token(s)\n",
      "\n",
      "GPT-2 Token Counts:\n",
      "rizz: 2 token(s)\n",
      "girl dinner: 2 token(s)\n",
      "delulu: 2 token(s)\n",
      "beige flag: 3 token(s)\n",
      "situationship: 3 token(s)\n",
      "sigma: 2 token(s)\n",
      "main character: 2 token(s)\n",
      "quiet luxury: 2 token(s)\n",
      "npc: 2 token(s)\n",
      "no thoughts, head empty: 5 token(s)\n",
      "mid: 1 token(s)\n",
      "feral: 2 token(s)\n",
      "canon event: 2 token(s)\n",
      "ate and left no crumbs: 6 token(s)\n",
      "he's just a guy: 5 token(s)\n",
      "loud budgeting: 4 token(s)\n",
      "chronically online: 3 token(s)\n",
      "corecore: 2 token(s)\n",
      "ick: 1 token(s)\n",
      "male manipulator music: 4 token(s)\n",
      "Harvard travel ban: 4 token(s)\n",
      "liberalism is a mental disorder: 6 token(s)\n",
      "NPC energy: 3 token(s)\n",
      "girlboss: 2 token(s)\n",
      "\n",
      "Differences in Tokenization:\n",
      "lit: GPT-4: 1, GPT-2: 1\n",
      "fam: GPT-4: 1, GPT-2: 1\n",
      "vibe: GPT-4: 2, GPT-2: 2\n",
      "slay: GPT-4: 2, GPT-2: 2\n",
      "flex: GPT-4: 1, GPT-2: 1\n",
      "skrrt: GPT-4: 3, GPT-2: 3\n",
      "skibidi: GPT-4: 3, GPT-2: 3\n",
      "sigma: GPT-4: 1, GPT-2: 2\n",
      "delulu: GPT-4: 2, GPT-2: 2\n",
      "sus: GPT-4: 1, GPT-2: 2\n",
      "bussin: GPT-4: 3, GPT-2: 3\n",
      "cap: GPT-4: 1, GPT-2: 1\n",
      "rizz: GPT-4: 2, GPT-2: 2\n",
      "girl dinner: GPT-4: 2, GPT-2: 2\n",
      "delulu: GPT-4: 2, GPT-2: 2\n",
      "beige flag: GPT-4: 3, GPT-2: 3\n",
      "situationship: GPT-4: 2, GPT-2: 3\n",
      "sigma: GPT-4: 1, GPT-2: 2\n",
      "main character: GPT-4: 2, GPT-2: 2\n",
      "quiet luxury: GPT-4: 2, GPT-2: 2\n",
      "npc: GPT-4: 1, GPT-2: 2\n",
      "no thoughts, head empty: GPT-4: 5, GPT-2: 5\n",
      "mid: GPT-4: 1, GPT-2: 1\n",
      "feral: GPT-4: 2, GPT-2: 2\n",
      "canon event: GPT-4: 2, GPT-2: 2\n",
      "ate and left no crumbs: GPT-4: 5, GPT-2: 6\n",
      "he's just a guy: GPT-4: 5, GPT-2: 5\n",
      "loud budgeting: GPT-4: 3, GPT-2: 4\n",
      "chronically online: GPT-4: 3, GPT-2: 3\n",
      "corecore: GPT-4: 2, GPT-2: 2\n",
      "ick: GPT-4: 1, GPT-2: 1\n",
      "male manipulator music: GPT-4: 4, GPT-2: 4\n",
      "Harvard travel ban: GPT-4: 4, GPT-2: 4\n",
      "liberalism is a mental disorder: GPT-4: 7, GPT-2: 6\n",
      "NPC energy: GPT-4: 2, GPT-2: 3\n",
      "girlboss: GPT-4: 2, GPT-2: 2\n"
     ]
    }
   ],
   "source": [
    "# print token counts for gpt-4\n",
    "print(\"GPT-4 Token Counts:\")\n",
    "for word, count in zip(trending_slang_terms, count_tokens(trending_slang_terms, gpt4_tokenizer)):\n",
    "    print(f\"{word}: {count} token(s)\")\n",
    "# print token counts for gpt-2\n",
    "print(\"\\nGPT-2 Token Counts:\")\n",
    "for word, count in zip(trending_slang_terms, count_tokens(trending_slang_terms, gpt2_tokenizer)):\n",
    "    print(f\"{word}: {count} token(s)\")\n",
    "\n",
    "# print differences in tokenization\n",
    "print(\"\\nDifferences in Tokenization:\")\n",
    "for word in genz_words + trending_slang_terms:\n",
    "    gpt4_tokens = gpt4_tokenizer.encode(word)\n",
    "    gpt2_tokens = gpt2_tokenizer.encode(word)\n",
    "    if gpt4_tokens != gpt2_tokens:\n",
    "        print(f\"{word}: GPT-4: {len(gpt4_tokens)}, GPT-2: {len(gpt2_tokens)}\")\n",
    "    else:\n",
    "        print(f\"{word}: No difference in tokenization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
